{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BdItkng0RoAg"
   },
   "source": [
    "# Action Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "qFlE2ioJvmZk"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from random import shuffle\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wm3Swol_ZwOm"
   },
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_rootdir=\"./ReCompress_Videos\"\n",
    "mask_rootdir=\"./puppet_mask\"\n",
    "pose_rootdir=\"./joint_positions\"\n",
    "\n",
    "video_pathes=[]\n",
    "mask_pathes=[]\n",
    "pose_pathes=[]\n",
    "for root, dirs, files in os.walk(video_rootdir):\n",
    "    for file in files:\n",
    "        if file[0].startswith(\".\") or root.endswith('.AppleDouble'):\n",
    "            continue\n",
    "        video_pathes.append(os.path.join(root, file))\n",
    "\n",
    "for root, dirs, files in os.walk(mask_rootdir):\n",
    "    for file in files:\n",
    "        if file[0].startswith(\".\") or root.endswith('.AppleDouble'):\n",
    "            continue\n",
    "        mask_pathes.append(os.path.join(root, file)) \n",
    "\n",
    "for root, dirs, files in os.walk(pose_rootdir):\n",
    "    for file in files:\n",
    "        if file[0].startswith(\".\") or root.endswith('.AppleDouble'):\n",
    "            continue\n",
    "        pose_pathes.append(os.path.join(root, file))         \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_pathes_train, video_pathes_valid, mask_pathes_train, mask_pathes_valid, pose_pathes_train, pose_pathes_valid = \\\n",
    "    train_test_split(video_pathes, mask_pathes, pose_pathes, test_size=0.01)\n",
    "class_names=[name for name in os.listdir(video_rootdir) if not name.startswith(\".\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JHMDB(torch.utils.data.Dataset):\n",
    "    def __init__(self, video_pathes, mask_pathes, pose_pathes, class_names):\n",
    "        \n",
    "        self.data = {'video': [], 'label': [], 'mask':[], 'pose':[], 'scale':[]}\n",
    "        \n",
    "        self.classdict = {}\n",
    "        for i, x in enumerate(class_names):\n",
    "            self.classdict[x] = i\n",
    "\n",
    "        video_num=len(video_pathes)\n",
    "        mask_num=len(mask_pathes)\n",
    "\n",
    "        for i in range(video_num):\n",
    "            video=[]\n",
    "            cap = cv2.VideoCapture(video_pathes[i])\n",
    "            has_frame=True\n",
    "            while(has_frame):\n",
    "                _, frame = cap.read()\n",
    "                has_frame = frame is not None\n",
    "\n",
    "                if has_frame:\n",
    "                    frame = cv2.resize(frame, (112, 112), interpolation = cv2.INTER_CUBIC) # (112, 112, 3)\n",
    "                    #frame = np.transpose(frame, (2, 0, 1)) # (3, 112, 112)\n",
    "                    video.append(frame)\n",
    "            cap.release()\n",
    "            self.data['video'].append(video)\n",
    "\n",
    "            mask_mat = loadmat(mask_pathes[i]) \n",
    "            masks = cv2.resize(mask_mat['part_mask'], (112, 112), interpolation = cv2.INTER_CUBIC) # (112, 112, F)\n",
    "            self.data['mask'].append(masks)\n",
    "            self.data['label'].append(video_pathes[i].split('/')[-2])\n",
    "            pose_mat = loadmat(pose_pathes[i])['pos_img']\n",
    "            scale = loadmat(pose_pathes[i])['scale']\n",
    "            self.data['pose'].append(pose_mat)\n",
    "            self.data['scale'].append(scale[0]) # redundant dim\n",
    "            \n",
    "            \n",
    "    def _compute_mean(self):\n",
    "        meanstd_file = './data/jhmdbmean'\n",
    "        if isfile(meanstd_file):\n",
    "            meanstd = torch.load(meanstd_file)\n",
    "        else:\n",
    "            mean = torch.zeros(3)\n",
    "            std = torch.zeros(3)\n",
    "            for videos in self.data['video']:\n",
    "                for img in videos:\n",
    "                    # HxWxC by now\n",
    "                    # TODO: to be changed\n",
    "                    mean += img.view(img.size(0), -1).mean(1)\n",
    "                    std += img.view(img.size(0), -1).std(1)\n",
    "            mean /= len(self.train)\n",
    "            std /= len(self.train)\n",
    "            meanstd = {\n",
    "                'mean': mean,\n",
    "                'std': std,\n",
    "                }\n",
    "            torch.save(meanstd, meanstd_file)\n",
    "        if self.is_train:\n",
    "            print('    Mean: %.4f, %.4f, %.4f' % (meanstd['mean'][0], meanstd['mean'][1], meanstd['mean'][2]))\n",
    "            print('    Std:  %.4f, %.4f, %.4f' % (meanstd['std'][0], meanstd['std'][1], meanstd['std'][2]))\n",
    "            \n",
    "        return meanstd['mean'], meanstd['std']\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # video (F, C, 112, 112) to be reshaped on the fly\n",
    "        # label scala, \n",
    "        # mask (112, 112, F)\n",
    "        # pose (2, 15, F)\n",
    "        # scale (F)\n",
    "        # randomly select 15 consecutive frames (F = 15)\n",
    "        frame_num = self.data['mask'][index].shape[2]\n",
    "        F = 15\n",
    "        start_frame = np.random.randint(0, high=frame_num-F+1)\n",
    "        \n",
    "        # change pose position according to resize\n",
    "        pose_data = torch.from_numpy(self.data['pose'][index][:,:,start_frame:start_frame+F].astype('float'))\n",
    "        pose_data[0,:,:] = pose_data[0,:,:] * 112 / 240\n",
    "        pose_data[1,:,:] = pose_data[1,:,:] * 112 / 320\n",
    "        \n",
    "        return torch.from_numpy(np.array(self.data['video'][index][start_frame:start_frame+F])).int(), \\\n",
    "            torch.LongTensor([self.classdict[self.data['label'][index]]]), \\\n",
    "            torch.from_numpy(self.data['mask'][index][:,:,start_frame:start_frame+F].astype('float')), \\\n",
    "            pose_data, \\\n",
    "            torch.from_numpy(self.data['scale'][index][start_frame:start_frame+F].astype('float'))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data['scale'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_dataset.data['video'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = JHMDB(video_pathes_train, mask_pathes_train, pose_pathes_train, class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataset = JHMDB(video_pathes_valid, mask_pathes_valid, pose_pathes_valid, class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pose0 \n",
      "(0 ,.,.) = \n",
      "\n",
      "Columns 0 to 6 \n",
      "    73.2988   73.1375   75.1579   75.1575   85.1226   85.1210   81.2326\n",
      "   85.9737   82.8679   87.3984   87.3984   85.7549   85.7581   76.3919\n",
      "   78.9094   78.9198   77.2249   77.2266   80.0737   80.0678   74.1840\n",
      "   89.2000   89.7714   89.7714   89.7714  100.6286  100.6286   99.4857\n",
      "   52.5143   52.5143   52.5143   52.5143   59.3714   64.5143   64.5143\n",
      "  100.9143  100.9143  103.2000  103.2000  103.2000  100.3429   93.4858\n",
      "   77.0857   79.3711   81.6572   81.6572   81.0857   81.0857   73.0857\n",
      "   79.0161   71.7272   70.5931   70.5938   99.8437   99.8411  115.2831\n",
      "   35.4909   32.6325   32.5019   32.4997   39.5206   52.0288   55.4611\n",
      "  108.5010  114.2172  121.6837  121.6854  127.5623  128.8135  122.5601\n",
      "   59.1240   60.3645   59.3239   59.3240   65.2265   68.6559   73.5048\n",
      "   36.5838   35.3158   32.9698   32.9401   68.6881   82.3877   89.8667\n",
      "   33.0639   30.7856   24.8418   24.8338   69.0412   76.1817   87.1440\n",
      "  133.4709  135.1547  136.1002  136.0993  146.3707  147.3512  137.0660\n",
      "   46.1553   43.6530   42.6495   42.6535   56.2258   61.3843   61.3892\n",
      "\n",
      "Columns 7 to 13 \n",
      "    71.9919   71.9945   58.2874   58.2920   49.0234   49.0426   49.0417\n",
      "   73.1591   73.1591   62.2824   62.2732   58.5246   56.7719   56.7719\n",
      "   66.8003   66.7900   58.8492   58.8594   49.4395   52.3034   52.3073\n",
      "   90.3428   90.3428   73.2000   57.8060   42.3428   35.4857   35.4857\n",
      "   67.3714   67.3714   66.3863   66.2286   62.2286   62.2286   62.2286\n",
      "   83.7715   83.7715   67.2001   67.2001   62.6287   60.3427   60.3429\n",
      "   72.5143   72.5143   61.6571   61.6571   57.6571   53.6571   53.6571\n",
      "  110.4226  110.4161   98.4807   83.1280   60.3931   49.4394   49.4211\n",
      "   86.3737   86.3715   88.1380   85.7291   77.3250   82.6691   82.6660\n",
      "  114.9866  114.9872  103.7023  103.7030  103.3934  102.7110  102.7153\n",
      "   73.5046   73.5041   73.3324   64.7603   64.7912   57.2602   57.2602\n",
      "  120.7899  120.7910  128.7790  112.4143   83.7018   67.7326   67.7297\n",
      "  117.2528  117.2533  121.6825  113.7490   88.2209   69.4507   69.4365\n",
      "  134.4865  134.4889  113.9798  113.9799  113.9165  113.9174  113.9182\n",
      "   61.3962   61.4011   61.6807   55.4089   55.3708   55.3717   55.3724\n",
      "\n",
      "Columns 14 to 14 \n",
      "    51.4268\n",
      "   54.8610\n",
      "   49.6370\n",
      "   28.6286\n",
      "   70.8000\n",
      "   59.7715\n",
      "   52.5143\n",
      "   31.9073\n",
      "   69.6374\n",
      "   98.1452\n",
      "   48.6095\n",
      "   35.5764\n",
      "   43.2331\n",
      "  113.9194\n",
      "   55.3694\n",
      "\n",
      "(1 ,.,.) = \n",
      "\n",
      "Columns 0 to 6 \n",
      "    86.0309   85.1631   91.1738   91.1766  104.2611  104.0969   99.9377\n",
      "  153.5383  151.8452  156.9667  156.9667  169.0777  169.4063  168.0102\n",
      "   76.0527   76.0363   81.0591   81.0482   95.7645   95.7523   88.5529\n",
      "  112.3428  115.7714  118.0571  118.0571  114.0571  114.0571  108.9143\n",
      "   95.4857   95.4857  100.6286  100.6286  115.4857  118.9143  118.9143\n",
      "  164.0001  164.0001  176.5715  176.5715  186.2858  190.8572  188.5715\n",
      "  174.2285  174.8009  178.8000  178.8000  186.2285  186.2285  186.7999\n",
      "  142.5070  139.3655  140.7406  140.7399  137.9635  137.9583  121.7611\n",
      "   95.8635   88.4352   95.5758   95.5826  156.3419  161.5988  141.5824\n",
      "  208.6210  210.9146  222.3215  222.3257  231.2977  233.3941  232.8158\n",
      "  226.5279  229.7285  232.4560  232.4560  241.7965  243.5081  245.7574\n",
      "  133.6833  125.5531  126.4657  126.4544  143.5545  150.9875  136.1700\n",
      "  129.4618  120.6780  122.5711  122.5992  143.3833  153.2381  137.2422\n",
      "  254.8247  259.7738  266.7480  266.7450  273.3325  275.5477  278.4061\n",
      "  270.1610  275.1734  277.9045  277.8936  287.1467  290.8486  290.8323\n",
      "\n",
      "Columns 7 to 13 \n",
      "    95.5652   95.5692   90.3732   90.4577   96.8943   96.8425   96.8463\n",
      "  166.4696  166.4696  163.7107  163.5417  166.6686  168.4864  168.4864\n",
      "   88.1020   88.0863   87.8088   87.7633   88.5601   85.6510   85.6361\n",
      "  100.9143  100.9143  104.9143  105.4861  108.9143  108.9143  108.9143\n",
      "  129.2000  129.2000  124.1826  124.0571  121.2000  116.0571  116.0571\n",
      "  188.5715  188.5715  190.8572  190.8572  194.8573  197.1428  197.1429\n",
      "  186.7999  186.7999  186.7999  186.7999  187.3714  190.7999  190.7999\n",
      "  107.3180  107.3159  106.0292  105.7895  112.1449  111.8142  111.8104\n",
      "  166.4866  166.4822  141.4225  129.9653  125.8669  103.1185  103.1207\n",
      "  232.8683  232.8691  231.9616  231.9624  231.7449  236.2385  236.2428\n",
      "  245.7481  245.7467  244.5822  245.7203  245.9376  252.5362  252.5315\n",
      "  149.2044  149.2087  116.1997   95.0251   86.3224   76.6641   76.6697\n",
      "  155.5743  155.5741  120.2392   98.9262   91.8783   79.6886   79.6633\n",
      "  270.8806  270.8853  279.7162  279.7169  279.4420  279.4453  279.4483\n",
      "  290.8063  290.7882  289.7245  290.8351  291.0165  290.9979  290.9840\n",
      "\n",
      "Columns 14 to 14 \n",
      "    98.3039\n",
      "  169.5649\n",
      "   90.2510\n",
      "  119.7715\n",
      "  116.6286\n",
      "  197.7143\n",
      "  191.9428\n",
      "   97.0589\n",
      "   94.2336\n",
      "  240.8981\n",
      "  255.4596\n",
      "   66.2348\n",
      "   71.7074\n",
      "  279.4511\n",
      "  290.9684\n",
      "[torch.DoubleTensor of size 2x15x15]\n",
      "\n",
      "pose1 \n",
      "(0 ,.,.) = \n",
      "\n",
      "Columns 0 to 6 \n",
      "    34.2061   34.1308   35.0737   35.0735   39.7239   39.7231   37.9086\n",
      "   40.1211   38.6717   40.7859   40.7859   40.0190   40.0205   35.6496\n",
      "   36.8244   36.8292   36.0383   36.0391   37.3677   37.3650   34.6192\n",
      "   41.6267   41.8933   41.8933   41.8933   46.9600   46.9600   46.4267\n",
      "   24.5067   24.5067   24.5067   24.5067   27.7067   30.1067   30.1067\n",
      "   47.0933   47.0933   48.1600   48.1600   48.1600   46.8267   43.6267\n",
      "   35.9733   37.0399   38.1067   38.1067   37.8400   37.8400   34.1067\n",
      "   36.8742   33.4727   32.9435   32.9438   46.5937   46.5925   53.7988\n",
      "   16.5624   15.2285   15.1675   15.1665   18.4430   24.2801   25.8818\n",
      "   50.6338   53.3014   56.7857   56.7865   59.5291   60.1129   57.1947\n",
      "   27.5912   28.1701   27.6845   27.6845   30.4390   32.0394   34.3022\n",
      "   17.0724   16.4807   15.3859   15.3721   32.0544   38.4476   41.9378\n",
      "   15.4298   14.3666   11.5928   11.5891   32.2192   35.5515   40.6672\n",
      "   62.2864   63.0722   63.5134   63.5130   68.3063   68.7639   63.9641\n",
      "   21.5391   20.3714   19.9031   19.9050   26.2387   28.6460   28.6483\n",
      "\n",
      "Columns 7 to 13 \n",
      "    33.5962   33.5974   27.2008   27.2029   22.8776   22.8866   22.8861\n",
      "   34.1409   34.1409   29.0651   29.0608   27.3115   26.4935   26.4935\n",
      "   31.1735   31.1687   27.4630   27.4677   23.0718   24.4083   24.4101\n",
      "   42.1600   42.1600   34.1600   26.9761   19.7600   16.5600   16.5600\n",
      "   31.4400   31.4400   30.9803   30.9067   29.0400   29.0400   29.0400\n",
      "   39.0934   39.0934   31.3600   31.3600   29.2267   28.1599   28.1600\n",
      "   33.8400   33.8400   28.7733   28.7733   26.9067   25.0400   25.0400\n",
      "   51.5305   51.5275   45.9576   38.7931   28.1835   23.0717   23.0632\n",
      "   40.3077   40.3067   41.1311   40.0069   36.0850   38.5789   38.5775\n",
      "   53.6604   53.6607   48.3944   48.3947   48.2503   47.9318   47.9338\n",
      "   34.3022   34.3019   34.2218   30.2215   30.2359   26.7214   26.7214\n",
      "   56.3686   56.3691   60.0969   52.4600   39.0608   31.6086   31.6072\n",
      "   54.7180   54.7182   56.7852   53.0829   41.1698   32.4103   32.4037\n",
      "   62.7604   62.7615   53.1906   53.1906   53.1611   53.1615   53.1618\n",
      "   28.6516   28.6538   28.7843   25.8575   25.8397   25.8401   25.8404\n",
      "\n",
      "Columns 14 to 14 \n",
      "    23.9992\n",
      "   25.6018\n",
      "   23.1639\n",
      "   13.3600\n",
      "   33.0400\n",
      "   27.8934\n",
      "   24.5067\n",
      "   14.8901\n",
      "   32.4974\n",
      "   45.8011\n",
      "   22.6844\n",
      "   16.6023\n",
      "   20.1754\n",
      "   53.1624\n",
      "   25.8390\n",
      "\n",
      "(1 ,.,.) = \n",
      "\n",
      "Columns 0 to 6 \n",
      "    30.1108   29.8071   31.9108   31.9118   36.4914   36.4339   34.9782\n",
      "   53.7384   53.1458   54.9383   54.9383   59.1772   59.2922   58.8036\n",
      "   26.6184   26.6127   28.3707   28.3669   33.5176   33.5133   30.9935\n",
      "   39.3200   40.5200   41.3200   41.3200   39.9200   39.9200   38.1200\n",
      "   33.4200   33.4200   35.2200   35.2200   40.4200   41.6200   41.6200\n",
      "   57.4000   57.4000   61.8000   61.8000   65.2000   66.8000   66.0000\n",
      "   60.9800   61.1803   62.5800   62.5800   65.1800   65.1800   65.3800\n",
      "   49.8775   48.7779   49.2592   49.2590   48.2872   48.2854   42.6164\n",
      "   33.5522   30.9523   33.4515   33.4539   54.7197   56.5596   49.5538\n",
      "   73.0173   73.8201   77.8125   77.8140   80.9542   81.6879   81.4855\n",
      "   79.2848   80.4050   81.3596   81.3596   84.6288   85.2278   86.0151\n",
      "   46.7892   43.9436   44.2630   44.2590   50.2441   52.8456   47.6595\n",
      "   45.3116   42.2373   42.8999   42.9097   50.1842   53.6333   48.0348\n",
      "   89.1887   90.9208   93.3618   93.3608   95.6664   96.4417   97.4421\n",
      "   94.5564   96.3107   97.2666   97.2628  100.5013  101.7970  101.7913\n",
      "\n",
      "Columns 7 to 13 \n",
      "    33.4478   33.4492   31.6306   31.6602   33.9130   33.8949   33.8962\n",
      "   58.2643   58.2643   57.2987   57.2396   58.3340   58.9702   58.9702\n",
      "   30.8357   30.8302   30.7331   30.7171   30.9960   29.9779   29.9726\n",
      "   35.3200   35.3200   36.7200   36.9201   38.1200   38.1200   38.1200\n",
      "   45.2200   45.2200   43.4639   43.4200   42.4200   40.6200   40.6200\n",
      "   66.0000   66.0000   66.8000   66.8000   68.2000   69.0000   69.0000\n",
      "   65.3800   65.3800   65.3800   65.3800   65.5800   66.7800   66.7800\n",
      "   37.5613   37.5606   37.1102   37.0263   39.2507   39.1350   39.1336\n",
      "   58.2703   58.2688   49.4979   45.4879   44.0534   36.0915   36.0922\n",
      "   81.5039   81.5042   81.1866   81.1869   81.1107   82.6835   82.6850\n",
      "   86.0118   86.0113   85.6038   86.0021   86.0782   88.3877   88.3860\n",
      "   52.2215   52.2230   40.6699   33.2588   30.2129   26.8324   26.8344\n",
      "   54.4510   54.4509   42.0837   34.6242   32.1574   27.8910   27.8822\n",
      "   94.8082   94.8099   97.9007   97.9009   97.8047   97.8059   97.8069\n",
      "  101.7822  101.7759  101.4036  101.7923  101.8558  101.8493  101.8444\n",
      "\n",
      "Columns 14 to 14 \n",
      "    34.4064\n",
      "   59.3477\n",
      "   31.5878\n",
      "   41.9200\n",
      "   40.8200\n",
      "   69.2000\n",
      "   67.1800\n",
      "   33.9706\n",
      "   32.9818\n",
      "   84.3143\n",
      "   89.4109\n",
      "   23.1822\n",
      "   25.0976\n",
      "   97.8079\n",
      "  101.8389\n",
      "[torch.DoubleTensor of size 2x15x15]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for x in valid_dataset:\n",
    "    #print(x)\n",
    "    #if i == 100:\n",
    "    #print(x)\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "    batch_size=10, shuffle=True)\n",
    "    #num_workers=2, pin_memory=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_loader = torch.utils.data.DataLoader(valid_dataset,\n",
    "    batch_size=5, shuffle=True)\n",
    "    #num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 15, 112, 112])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 112, 112, 15])\n",
      "torch.Size([5, 2, 15, 15])\n",
      "torch.Size([5, 15])\n"
     ]
    }
   ],
   "source": [
    "for x in valid_loader:\n",
    "    # transpose \n",
    "    print(x[0].transpose(4,3).transpose(3,2).transpose(2,1).size())\n",
    "    for t in x[1:]:\n",
    "        print(t.size())\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OScFNcIpZ0-A"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "5C8egG-_Z2Rg"
   },
   "outputs": [],
   "source": [
    "class C3D(nn.Module):\n",
    "    \"\"\"\n",
    "    The C3D network as described in [1].\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(C3D, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv3d(3, 64, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.pool1 = nn.MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2))\n",
    "\n",
    "        self.conv2 = nn.Conv3d(64, 128, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.pool2 = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
    "\n",
    "        self.conv3a = nn.Conv3d(128, 256, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.conv3b = nn.Conv3d(256, 256, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.pool3 = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
    "\n",
    "        self.conv4a = nn.Conv3d(256, 512, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.conv4b = nn.Conv3d(512, 512, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.pool4 = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
    "\n",
    "        self.conv5a = nn.Conv3d(512, 512, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.conv5b = nn.Conv3d(512, 512, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.pool5 = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=(0, 1, 1))\n",
    "\n",
    "        self.fc6 = nn.Linear(8192, 4096)\n",
    "        self.fc7 = nn.Linear(4096, 4096)\n",
    "        self.fc8 = nn.Linear(4096, 21)\n",
    "\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        h = self.relu(self.conv1(x))\n",
    "        h = self.pool1(h)\n",
    "\n",
    "        h = self.relu(self.conv2(h))\n",
    "        h = self.pool2(h)\n",
    "\n",
    "        h = self.relu(self.conv3a(h))\n",
    "        h = self.relu(self.conv3b(h))\n",
    "        h = self.pool3(h)\n",
    "\n",
    "        h = self.relu(self.conv4a(h))\n",
    "        h = self.relu(self.conv4b(h))\n",
    "        h = self.pool4(h)\n",
    "\n",
    "        h = self.relu(self.conv5a(h))\n",
    "        h = self.relu(self.conv5b(h))\n",
    "        h = self.pool5(h)\n",
    "\n",
    "        h = h.view(-1, 8192)\n",
    "        h = self.relu(self.fc6(h))\n",
    "        h = self.dropout(h)\n",
    "        h = self.relu(self.fc7(h))\n",
    "        h = self.dropout(h)\n",
    "\n",
    "        logits = self.fc8(h)\n",
    "\n",
    "        return logits"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "C3D.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
