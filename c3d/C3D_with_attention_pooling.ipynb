{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "C3D with attention pooling.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "BdItkng0RoAg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Action Detection"
      ]
    },
    {
      "metadata": {
        "id": "sWXxaGE5RsYL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Set up enviornment"
      ]
    },
    {
      "metadata": {
        "id": "4ad7cfeXbEvR",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "179e69a8-c46f-49af-b7da-3235979c3f98",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525017805651,
          "user_tz": 240,
          "elapsed": 45563,
          "user": {
            "displayName": "Liying Zhao",
            "photoUrl": "//lh6.googleusercontent.com/-Z-XhGew1LZs/AAAAAAAAAAI/AAAAAAAAAAc/25ESbW0lzTk/s50-c-k-no/photo.jpg",
            "userId": "111692502787799215379"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!pip3 install torch torchvision"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://legacy.pypi.org/simple\n",
            "Collecting torch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/43/380514bd9663f1bf708abeb359b8b48d3fabb1c8e95bb3427a980a064c57/torch-0.4.0-cp36-cp36m-manylinux1_x86_64.whl (484.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 484.0MB 26kB/s \n",
            "tcmalloc: large alloc 1073750016 bytes == 0x5b12a000 @  0x7f56336941c4 0x46d6a4 0x5fcbcc 0x4c494d 0x54f3c4 0x553aaf 0x54e4c8 0x54f4f6 0x553aaf 0x54efc1 0x54f24d 0x553aaf 0x54efc1 0x54f24d 0x553aaf 0x54efc1 0x54f24d 0x551ee0 0x54e4c8 0x54f4f6 0x553aaf 0x54efc1 0x54f24d 0x551ee0 0x54efc1 0x54f24d 0x551ee0 0x54e4c8 0x54f4f6 0x553aaf 0x54e4c8\n",
            "\u001b[?25hCollecting torchvision\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/0d/f00b2885711e08bd71242ebe7b96561e6f6d01fdb4b9dcf4d37e2e13c5e1/torchvision-0.2.1-py2.py3-none-any.whl (54kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 9.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting pillow>=4.1.1 (from torchvision)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5f/4b/8b54ab9d37b93998c81b364557dff9f61972c0f650efa0ceaf470b392740/Pillow-5.1.0-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.0MB 14.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.2)\n",
            "Installing collected packages: torch, pillow, torchvision\n",
            "  Found existing installation: Pillow 4.0.0\n",
            "    Uninstalling Pillow-4.0.0:\n",
            "      Successfully uninstalled Pillow-4.0.0\n",
            "Successfully installed pillow-5.1.0 torch-0.4.0 torchvision-0.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "O-1f-0pLRx4q",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "27889a2b-a86b-4739-9a2c-6f197ee43cf2",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525017884100,
          "user_tz": 240,
          "elapsed": 20196,
          "user": {
            "displayName": "Liying Zhao",
            "photoUrl": "//lh6.googleusercontent.com/-Z-XhGew1LZs/AAAAAAAAAAI/AAAAAAAAAAc/25ESbW0lzTk/s50-c-k-no/photo.jpg",
            "userId": "111692502787799215379"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\r\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CsWHn7wpTHa-",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qFlE2ioJvmZk",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import scipy\n",
        "from scipy.io import loadmat\n",
        "from random import shuffle\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import cv2\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UhSE0KVCvRBQ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "os.chdir('drive/Colab_Notebooks/c3d/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wm3Swol_ZwOm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data Loader"
      ]
    },
    {
      "metadata": {
        "id": "XBSBLGHGmOts",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "outputId": "e620eae6-3deb-4ab2-c630-d77671e2e1cb",
        "executionInfo": {
          "status": "error",
          "timestamp": 1525018369698,
          "user_tz": 240,
          "elapsed": 184705,
          "user": {
            "displayName": "Liying Zhao",
            "photoUrl": "//lh6.googleusercontent.com/-Z-XhGew1LZs/AAAAAAAAAAI/AAAAAAAAAAc/25ESbW0lzTk/s50-c-k-no/photo.jpg",
            "userId": "111692502787799215379"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "video_rootdir=\"./ReCompress_Videos\"\n",
        "mask_rootdir=\"./puppet_mask\"\n",
        "pose_rootdir=\"./joint_positions\"\n",
        "\n",
        "video_pathes=[]\n",
        "mask_pathes=[]\n",
        "pose_pathes=[]\n",
        "for root, dirs, files in os.walk(video_rootdir):\n",
        "    for file in files:\n",
        "        video_pathes.append(os.path.join(root, file))\n",
        "\n",
        "for root, dirs, files in os.walk(mask_rootdir):\n",
        "    for file in files:\n",
        "        mask_pathes.append(os.path.join(root, file)) \n",
        "\n",
        "for root, dirs, files in os.walk(pose_rootdir):\n",
        "    for file in files:\n",
        "        pose_pathes.append(os.path.join(root, file))\n",
        "        \n",
        "video_pathes = sorted(video_pathes)\n",
        "mask_pathes = sorted(mask_pathes)\n",
        "pose_pathes = sorted(pose_pathes)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-6b7c70407cd7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mmask_pathes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpose_rootdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mpose_pathes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/os.py\u001b[0m in \u001b[0;36mwalk\u001b[0;34m(top, topdown, onerror, followlinks)\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0;31m# above.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfollowlinks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mislink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopdown\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monerror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollowlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0;31m# Recurse into sub-directories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/os.py\u001b[0m in \u001b[0;36mwalk\u001b[0;34m(top, topdown, onerror, followlinks)\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0;31m# above.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfollowlinks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mislink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopdown\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monerror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollowlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0;31m# Recurse into sub-directories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/os.py\u001b[0m in \u001b[0;36mwalk\u001b[0;34m(top, topdown, onerror, followlinks)\u001b[0m\n\u001b[1;32m    356\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m                     \u001b[0mentry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscandir_it\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "77wLIo1PwMPo",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "video_pathes_train, video_pathes_valid, mask_pathes_train, mask_pathes_valid, pose_pathes_train, pose_pathes_valid = train_test_split(video_pathes, mask_pathes, pose_pathes, test_size=0.3)\n",
        "class_names=[name for name in os.listdir(video_rootdir)]\n",
        "class_num=len(class_names)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FoF5wyy6xxak",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class JHMDB(torch.utils.data.Dataset):\n",
        "    def __init__(self, video_pathes, mask_pathes, pose_pathes, class_names, F = 15):\n",
        "        \n",
        "        self.data = {'video': [], 'label': [], 'mask':[], 'pose':[], 'scale':[]}\n",
        "        \n",
        "        self.classdict = {}\n",
        "        for i, x in enumerate(class_names):\n",
        "            self.classdict[x] = i\n",
        "\n",
        "        video_num=len(video_pathes)\n",
        "        mask_num=len(mask_pathes)\n",
        "\n",
        "        for i in range(video_num):\n",
        "            video=[]\n",
        "            cap = cv2.VideoCapture(video_pathes[i])\n",
        "            has_frame=True\n",
        "            while(has_frame):\n",
        "                _, frame = cap.read()\n",
        "                has_frame = frame is not None\n",
        "\n",
        "                if has_frame:\n",
        "                    frame = cv2.resize(frame, (112, 112), interpolation = cv2.INTER_CUBIC)\n",
        "                    video.append(frame)\n",
        "            cap.release()\n",
        "                    \n",
        "            self.data['video'].append(video)\n",
        "\n",
        "            mask_mat = loadmat(mask_pathes[i]) \n",
        "            masks = cv2.resize(mask_mat['part_mask'], (112, 112), interpolation = cv2.INTER_CUBIC) # (112, 112, F)\n",
        "            self.data['mask'].append(masks)\n",
        "            \n",
        "            self.data['label'].append(video_pathes[i].split('/')[-2])\n",
        "            \n",
        "            pose_mat = loadmat(pose_pathes[i])['pos_img']\n",
        "            scale = loadmat(pose_pathes[i])['scale']\n",
        "            self.data['pose'].append(pose_mat)\n",
        "            self.data['scale'].append(scale[0]) # redundant dim\n",
        "    \n",
        "    def _compute_mean(self):\n",
        "        meanstd_file = './data/jhmdbmean'\n",
        "        if os.path.isfile(meanstd_file):\n",
        "            meanstd = torch.load(meanstd_file)\n",
        "        else:\n",
        "            mean = torch.zeros(3)\n",
        "            std = torch.zeros(3)\n",
        "            for videos in self.data['video']:\n",
        "                for img in videos:\n",
        "                    # CxHxW\n",
        "                    mean += np.reshape(img, (img.shape(0), -1)).mean(1)\n",
        "                    std += np.reshape(img, (img.shape(0), -1)).std(1)\n",
        "            mean /= len(self.train)\n",
        "            std /= len(self.train)\n",
        "            meanstd = {\n",
        "                'mean': mean,\n",
        "                'std': std,\n",
        "                }\n",
        "            torch.save(meanstd, meanstd_file)\n",
        "        if self.is_train:\n",
        "            print('    Mean: %.4f, %.4f, %.4f' % (meanstd['mean'][0], meanstd['mean'][1], meanstd['mean'][2]))\n",
        "            print('    Std:  %.4f, %.4f, %.4f' % (meanstd['std'][0], meanstd['std'][1], meanstd['std'][2]))\n",
        "            \n",
        "        return meanstd['mean'], meanstd['std']\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        # video (C, F, 112, 112)\n",
        "        # mask (112, 112, F)\n",
        "        # pose (2, 15, F)\n",
        "        # scale (F)\n",
        "        # label (1), \n",
        "        # randomly select 15 consecutive frames (F = 15)\n",
        "        F = 15\n",
        "        frame_num = self.data['mask'][index].shape[2]\n",
        "        frame_shuffle=list(range(frame_num))\n",
        "        shuffle(frame_shuffle)\n",
        "        selected_frame=sorted(frame_shuffle[0:F])\n",
        "       \n",
        "        # change pose position according to resize\n",
        "        pose_data = torch.from_numpy(self.data['pose'][index][:,:,selected_frame].astype('float'))\n",
        "        pose_data[0,:,:] = pose_data[0,:,:] * 112 / 240\n",
        "        pose_data[1,:,:] = pose_data[1,:,:] * 112 / 320\n",
        "        \n",
        "        \n",
        "        video = np.transpose(np.array(self.data['video'][index])[selected_frame,:,:,:], (3, 0, 1, 2))\n",
        "        return torch.FloatTensor(video), \\\n",
        "            torch.from_numpy(self.data['mask'][index][:,:,selected_frame].astype('float')), \\\n",
        "            pose_data, \\\n",
        "            torch.from_numpy(self.data['scale'][index][selected_frame].astype('float')), \\\n",
        "            torch.LongTensor([self.classdict[self.data['label'][index]]])\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.data['scale'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C97rTDvdmhic",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "train_dataset = JHMDB(video_pathes_train, mask_pathes_train, pose_pathes_train, class_names)\n",
        "valid_dataset = JHMDB(video_pathes_valid, mask_pathes_valid, pose_pathes_valid, class_names)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_04LKQZi-qFi",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_dataset,batch_size=10, shuffle=True)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_dataset,batch_size=10, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OScFNcIpZ0-A",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Model"
      ]
    },
    {
      "metadata": {
        "id": "_7qtu-s7hxRL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "N \\* 3 \\* 15 \\* 112 \\* 112 --> N \\* 64 \\* 15 \\* 56 \\* 56 -->  N \\* 128 \\* 8 \\* 28 \\* 28 --> N \\* 256 \\* 4 \\* 14 \\* 14 --> N \\* 512 \\* 2 \\* 7 \\* 7 --> N \\* 512 \\* 1 \\* 4 \\* 4"
      ]
    },
    {
      "metadata": {
        "id": "5C8egG-_Z2Rg",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class C3D(nn.Module):\n",
        "    \"\"\"\n",
        "    The C3D network as described in [1].\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,class_num):\n",
        "        super(C3D, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv3d(3, 64, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
        "        self.pool1 = nn.MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2))\n",
        "\n",
        "        self.conv2 = nn.Conv3d(64, 128, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
        "        self.pool2 = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=(1, 0, 0))\n",
        "\n",
        "        self.conv3a = nn.Conv3d(128, 256, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
        "        self.conv3b = nn.Conv3d(256, 256, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
        "        self.pool3 = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
        "\n",
        "        self.conv4a = nn.Conv3d(256, 512, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
        "        self.conv4b = nn.Conv3d(512, 512, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
        "        self.pool4 = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
        "\n",
        "        self.conv5a = nn.Conv3d(512, 512, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
        "        self.conv5b = nn.Conv3d(512, 512, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
        "        self.pool5 = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=(0, 1, 1))\n",
        "\n",
        "        self.fc6 = nn.Linear(8192, 4096)\n",
        "        self.fc7 = nn.Linear(4096, 4096)\n",
        "        self.fc8 = nn.Linear(4096, class_num)\n",
        "\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "        self.softmax = nn.Softmax()\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        h = self.relu(self.conv1(x))\n",
        "        h = self.pool1(h)\n",
        "\n",
        "        h = self.relu(self.conv2(h))\n",
        "        h = self.pool2(h)\n",
        "\n",
        "        h = self.relu(self.conv3a(h))\n",
        "        h = self.relu(self.conv3b(h))\n",
        "        h = self.pool3(h)\n",
        "\n",
        "        h = self.relu(self.conv4a(h))\n",
        "        h = self.relu(self.conv4b(h))\n",
        "        h = self.pool4(h)\n",
        "\n",
        "        h = self.relu(self.conv5a(h))\n",
        "        h = self.relu(self.conv5b(h))\n",
        "        h = self.pool5(h)\n",
        "\n",
        "        h = h.view(-1, 8192)\n",
        "        h = self.relu(self.fc6(h))\n",
        "        h = self.dropout(h)\n",
        "        h = self.relu(self.fc7(h))\n",
        "        h = self.dropout(h)\n",
        "\n",
        "        logits = self.fc8(h)\n",
        "\n",
        "        return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w9lVmTKk4PbJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train"
      ]
    },
    {
      "metadata": {
        "id": "o7CtEPLz_2ZD",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def eval_video(net,test_video,test_label):\n",
        "    net.eval()\n",
        "    _, indices=torch.max(net(test_video),1)\n",
        "    correct_prediction=torch.eq(indices,test_label.squeeze(1)).data.sum()\n",
        "    return correct_prediction.cpu().numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b3WOsP0q4fF9",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "feaeab99-5328-44f4-f92f-b576d386a495",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524975324203,
          "user_tz": 240,
          "elapsed": 1100,
          "user": {
            "displayName": "Liying Zhao",
            "photoUrl": "//lh6.googleusercontent.com/-Z-XhGew1LZs/AAAAAAAAAAI/AAAAAAAAAAc/25ESbW0lzTk/s50-c-k-no/photo.jpg",
            "userId": "111692502787799215379"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss().cuda()\n",
        "net=C3D(class_num).cuda()\n",
        "print(net)\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=0.01)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C3D(\n",
            "  (conv1): Conv3d(3, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "  (pool1): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "  (pool2): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=(1, 0, 0), dilation=1, ceil_mode=False)\n",
            "  (conv3a): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "  (conv3b): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "  (pool3): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv4a): Conv3d(256, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "  (conv4b): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "  (pool4): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv5a): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "  (conv5b): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "  (pool5): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)\n",
            "  (fc6): Linear(in_features=8192, out_features=4096, bias=True)\n",
            "  (fc7): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "  (fc8): Linear(in_features=4096, out_features=21, bias=True)\n",
            "  (dropout): Dropout(p=0.5)\n",
            "  (relu): ReLU()\n",
            "  (softmax): Softmax()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eQCjvTQdhMXD",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def train(epoch,step,disp_interval):\n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "    step_cnt = 0\n",
        "    for index,x in enumerate(train_loader):\n",
        "        train_video=Variable(x[0]).cuda()\n",
        "        train_video_label=Variable(x[4]).cuda()\n",
        "        train_result=net(train_video)\n",
        "        \n",
        "        # forward\n",
        "        loss = criterion(train_result,train_video_label.squeeze(1))\n",
        "        train_loss += loss.data[0]\n",
        "        step_cnt += train_video_label.shape[0]\n",
        "        step += train_video_label.shape[0]\n",
        "        # backward pass and update\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        # Log to screen\n",
        "        if step % disp_interval == 0:\n",
        "            log_text = 'epoch %d, step %d, loss: %.4f' % (epoch, step, train_loss / step_cnt)\n",
        "            print(log_text)\n",
        "            train_loss = 0\n",
        "            step_cnt = 0\n",
        "        \n",
        "        # Evaluate the model\n",
        "        if step % eval_interval == 0:\n",
        "            test_size=0\n",
        "            correct_num=0\n",
        "            for y in train_loader:\n",
        "                test_video=Variable(y[0]).cuda()\n",
        "                test_video_label=Variable(y[4]).cuda()\n",
        "                test_size += test_video_label.shape[0]\n",
        "                correct_num += eval_video(net,test_video,test_video_label)\n",
        "            accuracy = correct_num/test_size*100 \n",
        "            print(accuracy) \n",
        "            \n",
        "    return step"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k-fVtzd5_E_8",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "step=0\n",
        "disp_interval=10\n",
        "eval_interval=100\n",
        "\n",
        "for epoch in range(100):\n",
        "    step += train(epoch,step,disp_interval)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}